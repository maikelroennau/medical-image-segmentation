{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2149\n",
    "\n",
    "epochs = 4\n",
    "batch_size = 16\n",
    "steps_per_epoch = 32\n",
    "effective_batches = steps_per_epoch * epochs\n",
    "effective_images = batch_size * steps_per_epoch\n",
    "\n",
    "height = 240 # 240 480 960 1920\n",
    "width = 320 # 320 640 1280 2560\n",
    "input_shape = (height, width, 3)\n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(batch_size=16, target_size=(1920, 2560), augmented_dir=\"dataset/augmentation/\", seed=2149):\n",
    "    datagen_arguments = dict(\n",
    "        # featurewise_center=True,\n",
    "        # featurewise_std_normalization=True,\n",
    "        rotation_range=50,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        fill_mode=\"nearest\", # reflect\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rescale=None\n",
    "    )\n",
    "\n",
    "    image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_arguments)\n",
    "    mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_arguments)\n",
    "\n",
    "    images = image_datagen.flow_from_directory(\n",
    "        directory=\"dataset/train/\",\n",
    "        target_size=target_size,\n",
    "        classes=[\"images\"],\n",
    "        class_mode=None,\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        # save_to_dir=f\"{augmented_dir}/images\",\n",
    "        save_prefix=\"image\",\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    masks = mask_datagen.flow_from_directory(\n",
    "        directory=\"dataset/train/\",\n",
    "        target_size=target_size,\n",
    "        classes=[\"masks\"],\n",
    "        class_mode=None,\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        # save_to_dir=f\"{augmented_dir}/masks\",\n",
    "        save_prefix=\"image\",\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def data_generator(images, masks):\n",
    "    for images, masks in zip(images, masks):\n",
    "        yield (images, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = data_loader(batch_size, (height, width))\n",
    "generator = data_generator(images, masks)\n",
    "\n",
    "# for i, batch in enumerate(generator):\n",
    "#     print(f\"Iteration {i}\")\n",
    "#     if i + 1 == effective_batches:\n",
    "#         break\n",
    "# assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_path = \"dataset/train/images/\"\n",
    "# masks_path = \"dataset/train/masks/\"\n",
    "\n",
    "# images = os.listdir(images_path)\n",
    "# masks = os.listdir(masks_path)\n",
    "# images.sort()\n",
    "# masks.sort()\n",
    "\n",
    "# number_of_images = len(images)\n",
    "\n",
    "# print(f\"Total images: {number_of_images}\")\n",
    "# print(f\"Target shape: {(number_of_images,) + input_shape}\")\n",
    "\n",
    "# images_tensor = np.empty((number_of_images,) + input_shape)\n",
    "# masks_tensor = np.empty((number_of_images,) + input_shape)\n",
    "\n",
    "# for i, (image, mask) in enumerate(zip(images, masks)):\n",
    "#     assert image.split(\".\")[0] == mask.split(\".\")[0], f\"Image and maks do not correspond: {image}, {mask}\"\n",
    "#     img = cv2.imread(os.path.join(images_path, image))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.resize(img, (width, height))\n",
    "#     images_tensor[i, :, :, :] = img\n",
    "\n",
    "#     msk = cv2.imread(os.path.join(masks_path, mask), cv2.IMREAD_GRAYSCALE)\n",
    "#     msk = cv2.cvtColor(msk, cv2.COLOR_BGR2RGB)\n",
    "#     msk = cv2.resize(msk, (width, height))\n",
    "#     masks_tensor[i, :, :, :] = msk\n",
    "\n",
    "# print(images_tensor.shape)\n",
    "# print(masks_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "    x = layers.experimental.preprocessing.Normalization()(x)\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=dice_coef_loss, metrics=[dice_coef, \"binary_accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model(input_shape=input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = os.path.join(\"checkpoints\", f\"{time.strftime('%Y%m%d%H%M%S')}\")\n",
    "os.makedirs(checkpoint_directory)\n",
    "\n",
    "with open(os.path.join(checkpoint_directory, \"hyperparameters.txt\"), \"w\") as hyperparameters:\n",
    "    hyperparameters.write(f\"Seed: {seed}\\n\")\n",
    "    hyperparameters.write(f\"Epochs: {epochs}\\n\")\n",
    "    hyperparameters.write(f\"Batch size: {batch_size}\\n\")\n",
    "    hyperparameters.write(f\"Steps per epoch: {steps_per_epoch}\\n\")\n",
    "    hyperparameters.write(f\"Effective batches: {effective_batches}\\n\")\n",
    "    hyperparameters.write(f\"Effective images: {effective_images}\\n\")\n",
    "    hyperparameters.write(f\"Input shape: {input_shape}\\n\")\n",
    "    hyperparameters.write(f\"Learning rate: {model.optimizer.get_config()['learning_rate']}\\n\")\n",
    "\n",
    "callbacks = [\n",
    "    #keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1,  mode=\"auto\", cooldown=1),\n",
    "    keras.callbacks.ModelCheckpoint(os.path.join(checkpoint_directory, \"epoch_{epoch}.h5\"), monitor=\"val_loss\", save_best_only=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(f\"Training start - {time.strftime('%x %X')}\")\n",
    "print(f\"  - Seed: {seed}\")\n",
    "print(f\"  - Epochs: {epochs}\")\n",
    "print(f\"  - Batch size: {batch_size}\")\n",
    "print(f\"  - Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"  - Effective batches: {effective_batches}\")\n",
    "print(f\"  - Effective images: {effective_images}\")\n",
    "print(f\"  - Input shape: {input_shape}\")\n",
    "print(f\"  - Learning rate: {model.optimizer.get_config()['learning_rate']}\")\n",
    "print(f\"  - Checkpoints saved at: {checkpoint_directory}\\n\")\n",
    "\n",
    "keras.backend.clear_session()\n",
    "history = model.fit(generator, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=callbacks)#, validation_data=val_ds)\n",
    "# history = model.fit(images_tensor, masks_tensor, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=callbacks)#, validation_data=val_ds)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nTraining end - {time.strftime('%x %X')}\")\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Duration: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "print(f\"  - Learning rate: {model.optimizer.get_config()['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = \"dataset/test/\"\n",
    "\n",
    "images = os.listdir(test_images_path)\n",
    "images = [image for image in images if not image.endswith(\"_prediction.jpg\")]\n",
    "\n",
    "test_images_tensor = np.empty((len(images), height, width, 3))\n",
    "original_shape = None\n",
    "\n",
    "for i, image_path in enumerate(images):\n",
    "    image = cv2.imread(os.path.join(test_images_path, image_path), cv2.IMREAD_COLOR)\n",
    "    original_shape = image.shape[:2][::-1]\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (width, height))\n",
    "    test_images_tensor[i, :, :, :] = image\n",
    "\n",
    "print(test_images_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = False\n",
    "\n",
    "if test_all:\n",
    "    for i in range(1, 60):\n",
    "        keras.backend.clear_session()\n",
    "        loaded_model = keras.models.load_model(f\"{checkpoint_directory}/epoch_{i}.h5\", custom_objects={\"dice_coef_loss\": dice_coef_loss, \"dice_coef\": dice_coef})\n",
    "        predictions = loaded_model.predict(test_images_tensor, verbose=1)\n",
    "        \n",
    "        for j, prediction in enumerate(predictions):\n",
    "            name = os.path.basename(images[j]).split(\".\")[0]\n",
    "            prediction = cv2.resize(prediction, original_shape)\n",
    "            cv2.imwrite(os.path.join(test_images_path, f\"{name}_prediction_{i}.jpg\"), prediction * 255)\n",
    "else:\n",
    "    loaded_model = keras.models.load_model(f\"{checkpoint_directory}/epoch_{epochs}.h5\", custom_objects={\"dice_coef_loss\": dice_coef_loss, \"dice_coef\": dice_coef})\n",
    "    predictions = loaded_model.predict(test_images_tensor, verbose=1)\n",
    "\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        name = os.path.basename(images[i]).split(\".\")[0]\n",
    "        prediction = cv2.resize(prediction, original_shape)\n",
    "        cv2.imwrite(os.path.join(test_images_path, f\"{name}_prediction.jpg\"), prediction * 255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
